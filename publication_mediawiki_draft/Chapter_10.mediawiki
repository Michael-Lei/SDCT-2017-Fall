Chapter 10 - Compiler I: Syntax Analysis

=Term list=
{|
|中文
|English
|-
|编译器
|a compiler
|-
|词法分析
|tokenization
|-
|语法分析
|syntax analysis
|-
|代码生成
|code generation
|-
|记号（编程语言的最小单位，包括符号、关键字、变量名称）
|a token
|-
|（编程语言的）符号
|a symbol
|-
|（编程语言的）关键字
|a keyword
|-
|（用户定义的）变量名、类名、函数名
|an identifier
|-
|递归
|recursion
|-
|递归下降（算法）
|recursive-descent
|-
|有限状态机
|a finite state machine
|-
|状态转移
|state transition
|-
|（编程语言的）句法
|syntax
|-
|缩进
|indentation
|}

=6.0 Introduction=
Items worth paying special attention to

In the last chapter, we discover that it is much easier to write programs in Jack language than in VM language. When it comes to high perplexity, video games for instance, it seems impractical if not using high level languages such as Jack. Again, we learn that abstraction enables us to handle complexity. 

Although programmers benefit from high-level languages, the computer does not. An extra step, called compilation, is needed to convert Jack codes into VM codes. Whenever you run a program after writing it in C++ or Java, a compiler plays its role in converting high-level codes to machine codes (in C++) or to VM codes (in Java). This conversion, involving a lot of knowledge, is usually not a easy job. 

Luckily, computer scientists have found it useful to divide this complex task, whose target language is VM codes, into roughly three stages: (See Figure 10.1 in textbook)
*tokenization: Extract tokens (symbols, keywords, constants, and identifiers) from the source code in Jack.
*syntax analysis: Analyze the syntax based on the tokens, and generate a syntax tree if no syntax errors occur in the source file. 
*code generation: Generate the target code in VM language according to the syntax tree. 

In this chapter, we focus on tokenization and syntax analysis. Code generation will be the topic of Chapter 11. 

=6.1 Background=
逻辑模型
=6.2 Syntax Analyzer Specification=

尽量依照原有的内容结构 Try to follow the original content structure
加入个人的学习体会  Include your own learning experience

The tokenizer is much easier to implement than the syntax analyzer is, so we discuss further on the syntax analyzer. We will come back to implementation of a tokenizer in section 6.3.1.  

Suppose the tokenization is done, and we have a list of tokens from the source code, each token belonging to one of the types (or lexical elements): 
*integer constant
*string constant
*keyword
*identifier
*symbol

See Figure 10.5 in textbook to learn how these types are defined. In fact, the same figure is also the syntax, itself enough for the syntax analyze. This figure serves as the design contract, by which our syntax analyzer is designed. 

Here we introduce two major ideas toword the problem. One is recursive descent, in which we construct the syntax tree by recursively expanding children nodes to some node in the tree; the other is RegEx match, in which we directly match specific patterns with those in Figure 10.5 using a powerful tool called RegEx, or regular expressions. 

==6.2.1 Recursive descent approach==

First of all, we should know that the codes in Jack programming language is hierarchical. For example, when we set indentation to the source code, each line of the code have its own level of indentation. On the top is the line defining the class, like <code>class Adder {</code>, which has no indents. Subordinate to it is the fields and subroutines, like <code>field int x, y;</code>, which has 1 indent (1 tab or 4 spaces). The declarations and statements in a subroutine, such as <code>return x + y;</code>, have 2 indents (2 tabs or 8 spaces), which means they are actually children of their parent subroutine in the syntax tree. The expression <code>x + y</code> subordinates to the <code>return</code> statement, and at the bottom are two terms <code>x</code> and <code>y</code>. 

<source lang="jack">
class Adder {
    field int x, y;
    method int add() {
        return x + y;
    }
}
</source>

The language, though human readable, is hierarchical, which is the feature of a syntax tree. Therefore, it is actually equivalent to the following syntax tree: 

<source lang="xml">
<class>
    <keyword>class</keyword>
    <identifier>Adder</identifier>
    <symbol>{</symbol>
    <classVarDec>
        <keyword>field</keyword>
        <keyword>int</keyword>
        <identifier>x</identifier>
        <symbol>,</symbol>
        <identifier>y</identifier>
        <symbol>;</symbol>
    </classVarDec>
    <subroutineDec>
        <keyword>method</keyword>
        <keyword>int</keyword>
        <identifier>add</identifier>
        <symbol>(</symbol>
        <parameterList>
        </parameterList>
        <symbol>)</symbol>
        <symbol>{</symbol>
        <statements>
            <returnStatement>
                <keyword>return</keyword>
                <expression>
                    <term>
                        <identifier>x</identifier>
                    </term>
                    <symbol>+</symbol>
                    <term>
                        <identifier>y</identifier>
                    </term>
                <symbol>;</symbol>
                </expression>
            </returnStatement>
        </statements>
        <symbol>}</symbol>
    </subroutineDec>
    <symbol>}</symbol>
</class>
</source>

Using recursion, we only focus on one level each time. When processing the <code>class</code> level, we inpterpret the code as follows: 

<source lang="xml">
<class>
    <keyword>class</keyword>
    <identifier>Adder</identifier>
    <symbol>{</symbol>
    <classVarDec>
        to be handled recursively
    </classVarDec>
    <subroutineDec>
        to be handled recursively
    </subroutineDec>
    <symbol>}</symbol>
</class>
</source>

This interpretation is identical to the "Program structure - class" syntax in our design contract Figure 10.5 in textbook. We do not handle of <code>classVarDecs</code> and <code>subroutineDecs</code> in a handler for <code>class</code>. Instead, we call their corresponding handlers in a recursive way. Since we begin recursion on the top level (class), we are actually moving down along a syntax tree, from root to bottom, expanding children from parents, so this approach is called a recursive descent. 

One more example. In the code above, when processing the <code>subroutineDec</code> level, we interpret it as follows:

<source lang="xml">
<subroutineDec>
    <keyword>method</keyword>
    <keyword>int</keyword>
    <identifier>add</identifier>
    <symbol>(</symbol>
    <parameterList>
        to be handled recursively
    </parameterList>
    <symbol>)</symbol>
    <symbol>{</symbol>
        to be handled recursively
    <symbol>}</symbol>
</subroutineDec>
</source>

Again, this recursive syntax tree corresponds to the "Program structure - subroutineDec" syntax in Figure 10.5 in textbook. 

==6.2.2 RegEx match approach==
(Group 1's work)

=6.3 Implementation using recursive descent=
Our implementation is in Java, a popular object-oriented programming language. The source code is public at <a href="https://github.com/kingium/JackCompiler">GitHub</a> with a readme file. It is equiped with a HTTP Web API, which can be deployed in any server with Java SE installed. 

Besides the Web API, our module <code>JackCompiler</code> consists of three modules. The modules <code>JackTokenizer</code> and <code>JackAnalyzer</code> are for this chapter. 

==6.3.1 The Tokenizer Module==
Source file in <code>./src/JackCompiler/JackTokenizer.java</code>

We scan the input Jack file twice. At the first time, we read in every single character from the source code, and store them in a list. All the commenting lines are omitted during this scan. 

At the second time, we tokenize the list of characters using a finite state machine. Each token type can be regarded as a state, with a default state in addition. Every time the main loop begins, the state machines is in the default state, and the cursor is at the beginning of the next token. Within each loop, we advance over one character, and check if it is a symbol, a digit, or a letter. Based on the type of the first character, We have different ways to determine how to advance the cursor in the next steps. For example, if it is a digit, we know that the token must be a interger constant, and we read as many digits as possible, until a blank or a symbol is met. Now we see why an identifier cannot begin with a digit in Jack: it helps the tokenizer to distinguish an integer constant from an identifier when it only scans the first character of the token. 

==6.3.2 The Analyzer Module==
This module takes a tokenizer as its input. It has several private methods, each one dealing with one case in our design contract (Figure 10.5 in textbook). 

The <code>analyze()</code> method is the entrance of syntax analyze, in which the <code>procClass()</code> method is called to process the class definition. In Figure 10.5 in textbook, the class definition is assumed to have the following structure: <code>'class' className '{' classVarDec* subroutineDec* '}'</code>. Therefore, in <code>procClass</code> method, we follow this structure, so the code goes like <a href="https://github.com/kingium/JackCompiler/blob/master/src/JackCompiler/JackAnalyzer.java">this</a>: 

<source lang="java">
private void procClass() throws JackCompilerException {
        tokenizer.advance();
        _assert(tokenizer.getTokenType() == JackTokenizer.TokenType.KEYWORD
                && tokenizer.getKeyWord() == JackTokenizer.KeyWord.CLASS);
        Element currNode = doc.createElement("class");
        currNode.appendChild(_createTextElement("keyword", "class"));

        procClassName(currNode);

        tokenizer.advance();
        _assert(tokenizer.getTokenType() == JackTokenizer.TokenType.SYMBOL
                && tokenizer.getSymbol() == '{');

        currNode.appendChild(_createTextElement("symbol", "{"));

        tokenizer.advance();
        procClassVarDecOrSubroutineDec(currNode);

        currNode.appendChild(_createTextElement("symbol", "}"));
        doc.appendChild(currNode);
    }
</source>

In the code, we call <code>tokenizer.advance()</code> to advance to the next token, and call <code>tokenizer.getToeknType()</code> and methods like <code>tokenizer.getKeyword()</code> to get the type and content of the token we just read. 

It is worth noting that we do not handle the variable declarations and subroutines directly in our <code>procClass()</code>. Instead, we call other methods recursively to process them, as can be seen in <code>procClassVarDecOrSubroutineDec(currNode);</code>. To put it simply, imagine that you are excuting the <code>procClass()</code> method: When you see the code <code>procClassVarDecOrSubroutineDec(currNode);</code>, you just call another method to handle it, and wait until that method finishes its work. After it returns, you continue excuting the next line. Hence, the function calls are hierarchical. We call this a recursive call, because the subordinate method (such as <code>procTerm</code>) may also call a method that called it (such as <code>procExpression</code>). For example, when handling the following code: 

<source lang="jack">
let a = x + (y + 1);
</source>

According to our design contract, <code>x + (y + 1)</code> is an expression, consisting of two terms <code>x</code> and <code>(y + 1)</code>. But <code>(y + 1)</code> is made up of <code>(</code> + <code>y + 1</code> and <code>)</code>. Here <code>y + 1</code> is also an expression, which consists of two terms </code>y</code> and <code>1</code>. In such circumstances, we function calls are like this: 

<source lang="jack">
procLetStatement            // let a = x + (y + 1);
    procTerm                // a
    procExpression          // x + (y + 1)
        procTerm            // x
        procTerm            // (y + 1)
            procExpression  // y + 1
                procTerm    // y
                procTerm    // 1
</source>


==6.3.3 Assembler for Programs with No Symbols==
==6.3.4 The SymbolTable Module==
==6.3.5 Assembler for Programs with Symbols==
=6.4 Perspective=
=6.5 Project=
讲解题目的关键点  Elaborate on key ideas for the project
=6.6 Glossary=
关键词
=6.7 References=
参考文献
=6.8 Additional Reading Material=
